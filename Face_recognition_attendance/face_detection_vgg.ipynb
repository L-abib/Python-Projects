{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python torch torchvision matplotlib facenet-pytorch\n"
      ],
      "metadata": {
        "id": "v_s9tH2CDhIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82d57c0-df6f-4e8d-ce6d-563a137c5da5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting numpy>=1.21.2 (from opencv-python)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "INFO: pip is looking at multiple versions of facenet-pytorch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.6.15)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, facenet-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed facenet-pytorch-2.5.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import copy\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "EZdHCNe-xvYH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIsdVfj2z8qu",
        "outputId": "cbdbeef3-9ae0-42a5-ede5-264a1b9ee8b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Face Dataset Class**"
      ],
      "metadata": {
        "id": "oSuxIrQKMQMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "        self.class_names = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "\n",
        "\n",
        "        self.mtcnn = MTCNN(keep_all=False, min_face_size=40, device=device)\n",
        "\n",
        "        print(\"Loading dataset and detecting faces...\")\n",
        "        for label, person in enumerate(self.class_names):\n",
        "            person_dir = os.path.join(root_dir, person)\n",
        "            for img_name in os.listdir(person_dir):\n",
        "                img_path = os.path.join(person_dir, img_name)\n",
        "                try:\n",
        "                    img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "                    face_tensor = self.mtcnn(img)\n",
        "\n",
        "                    if face_tensor is not None:\n",
        "                        face = transforms.ToPILImage()(face_tensor)\n",
        "                        self.data.append(face)\n",
        "                        self.labels.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not process image {img_path}: {e}\")\n",
        "        print(\"Dataset loaded successfully.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.labels[idx]"
      ],
      "metadata": {
        "id": "GUriXgvJD3wM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset from Drive**"
      ],
      "metadata": {
        "id": "HoY6XrvTMXrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/My Drive/faces_dataset\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "full_dataset = FaceDataset(root_dir=dataset_path, transform=transform)\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "print(f\"Total classes: {len(full_dataset.class_names)}\")\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "id": "m0jXB9L9EGnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3514b8b9-7bc3-4463-83dc-5f16b1e05a35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset and detecting faces...\n",
            "Dataset loaded successfully.\n",
            "Total classes: 5\n",
            "Training set size: 1540\n",
            "Validation set size: 385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup VGG16 Model**"
      ],
      "metadata": {
        "id": "lsUCEGx-MbxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.features[24:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "num_classes = len(full_dataset.class_names)\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOVbfd1TEUup",
        "outputId": "4b7468db-51f1-4981-be6a-5a7287bf6ffa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 153MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.24.weight\n",
            "features.24.bias\n",
            "features.26.weight\n",
            "features.26.bias\n",
            "features.28.weight\n",
            "features.28.bias\n",
            "classifier.0.weight\n",
            "classifier.0.bias\n",
            "classifier.3.weight\n",
            "classifier.3.bias\n",
            "classifier.6.weight\n",
            "classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the Model**"
      ],
      "metadata": {
        "id": "LQOzdny-MhHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 7\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, momentum=0.9, nesterov=True)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1, verbose=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_train += torch.sum(preds == labels.data)\n",
        "        total_train += inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_train\n",
        "    epoch_acc = correct_train.double() / total_train\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_val += torch.sum(preds == labels.data)\n",
        "            total_val += inputs.size(0)\n",
        "\n",
        "    epoch_val_loss = val_loss / total_val\n",
        "    epoch_val_acc = correct_val.double() / total_val\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Train Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f} | Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "    scheduler.step(epoch_val_loss)\n",
        "\n",
        "    if epoch_val_loss < best_val_loss:\n",
        "        print(f\"Validation loss decreased ({best_val_loss:.4f} --> {epoch_val_loss:.4f}). Saving model...\")\n",
        "        best_val_loss = epoch_val_loss\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"No improvement for {counter} epoch(s)\")\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n",
        "model_save_path = \"/content/drive/My Drive/models/face_recognition_vgg16_best.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Best model saved to: {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK0Akp9fEjMO",
        "outputId": "747b390e-c0f0-4106-8c4c-d8fe9732d947"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting model training...\n",
            "Epoch 01 | Train Loss: 0.2686, Acc: 0.9032 | Val Loss: 0.0081, Val Acc: 0.9974\n",
            "Validation loss decreased (inf --> 0.0081). Saving model...\n",
            "Epoch 02 | Train Loss: 0.0397, Acc: 0.9877 | Val Loss: 0.0069, Val Acc: 0.9974\n",
            "Validation loss decreased (0.0081 --> 0.0069). Saving model...\n",
            "Epoch 03 | Train Loss: 0.0220, Acc: 0.9935 | Val Loss: 0.0203, Val Acc: 0.9948\n",
            "No improvement for 1 epoch(s)\n",
            "Epoch 04 | Train Loss: 0.0029, Acc: 0.9994 | Val Loss: 0.0028, Val Acc: 0.9974\n",
            "Validation loss decreased (0.0069 --> 0.0028). Saving model...\n",
            "Epoch 05 | Train Loss: 0.0011, Acc: 1.0000 | Val Loss: 0.0055, Val Acc: 0.9974\n",
            "No improvement for 1 epoch(s)\n",
            "Epoch 06 | Train Loss: 0.0027, Acc: 0.9994 | Val Loss: 0.0004, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0028 --> 0.0004). Saving model...\n",
            "Epoch 07 | Train Loss: 0.0050, Acc: 0.9981 | Val Loss: 0.0004, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0004 --> 0.0004). Saving model...\n",
            "Epoch 08 | Train Loss: 0.0007, Acc: 1.0000 | Val Loss: 0.0002, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0004 --> 0.0002). Saving model...\n",
            "Epoch 09 | Train Loss: 0.0053, Acc: 0.9987 | Val Loss: 0.0007, Val Acc: 1.0000\n",
            "No improvement for 1 epoch(s)\n",
            "Epoch 10 | Train Loss: 0.0007, Acc: 1.0000 | Val Loss: 0.0001, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0002 --> 0.0001). Saving model...\n",
            "Epoch 11 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0001 --> 0.0000). Saving model...\n",
            "Epoch 12 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0037, Val Acc: 0.9974\n",
            "No improvement for 1 epoch(s)\n",
            "Epoch 13 | Train Loss: 0.0029, Acc: 0.9994 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 2 epoch(s)\n",
            "Epoch 14 | Train Loss: 0.0004, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0000 --> 0.0000). Saving model...\n",
            "Epoch 15 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0000 --> 0.0000). Saving model...\n",
            "Epoch 16 | Train Loss: 0.0003, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 1 epoch(s)\n",
            "Epoch 17 | Train Loss: 0.0002, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 2 epoch(s)\n",
            "Epoch 18 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 3 epoch(s)\n",
            "Epoch 19 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0001, Val Acc: 1.0000\n",
            "No improvement for 4 epoch(s)\n",
            "Epoch 20 | Train Loss: 0.0002, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 5 epoch(s)\n",
            "Epoch 21 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0000 --> 0.0000). Saving model...\n",
            "Epoch 22 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0000 --> 0.0000). Saving model...\n",
            "Epoch 23 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 1 epoch(s)\n",
            "Epoch 24 | Train Loss: 0.0003, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "Validation loss decreased (0.0000 --> 0.0000). Saving model...\n",
            "Epoch 25 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 1 epoch(s)\n",
            "Epoch 26 | Train Loss: 0.0000, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 2 epoch(s)\n",
            "Epoch 27 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0002, Val Acc: 1.0000\n",
            "No improvement for 3 epoch(s)\n",
            "Epoch 28 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 4 epoch(s)\n",
            "Epoch 29 | Train Loss: 0.0003, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 5 epoch(s)\n",
            "Epoch 30 | Train Loss: 0.0001, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 6 epoch(s)\n",
            "Epoch 31 | Train Loss: 0.0000, Acc: 1.0000 | Val Loss: 0.0000, Val Acc: 1.0000\n",
            "No improvement for 7 epoch(s)\n",
            "Early stopping triggered\n",
            "Best model saved to: /content/drive/My Drive/models/face_recognition_vgg16_best.pth\n"
          ]
        }
      ]
    }
  ]
}